"""
Diagnostic tool to detect data leakage in video frame datasets.

Checks for:
1. Temporal leakage: Same video frames in different splits
2. Visual similarity: Near-duplicate frames across splits
3. Performance unrealism: Suspiciously high metrics
"""

import pandas as pd
import numpy as np
from components.video_aware_split import extract_video_id


def diagnose_data_leakage(csv_path: str, seed: int = 42):
    """
    Comprehensive data leakage diagnosis for FLAME2 dataset.
    
    Args:
        csv_path: Path to CSV file
        seed: Random seed used for splitting
    """
    print("="*70)
    print("DATA LEAKAGE DIAGNOSTIC REPORT")
    print("="*70)
    print(f"CSV: {csv_path}")
    print(f"Seed: {seed}\n")
    
    # Load data
    df = pd.read_csv(csv_path)
    df['video_id'] = df['rgb_frame'].apply(extract_video_id)
    
    print(f"Total frames: {len(df)}")
    print(f"Unique videos: {df['video_id'].nunique()}\n")
    
    # Show video distribution
    video_frame_counts = df['video_id'].value_counts()
    print(f"Frames per video statistics:")
    print(f"  Mean:   {video_frame_counts.mean():.1f}")
    print(f"  Median: {video_frame_counts.median():.1f}")
    print(f"  Min:    {video_frame_counts.min()}")
    print(f"  Max:    {video_frame_counts.max()}\n")
    
    # Test old (leaky) splitting
    print("="*70)
    print("TEST 1: Frame-Level Random Split (Current Method - LEAKY)")
    print("="*70)
    
    from components.dataset import create_stratified_splits
    train_df, val_df, test_df = create_stratified_splits(
        csv_path,
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15,
        seed=seed,
        use_video_aware=False  # Old method
    )
    
    # Add video IDs
    train_df['video_id'] = train_df['rgb_frame'].apply(extract_video_id)
    val_df['video_id'] = val_df['rgb_frame'].apply(extract_video_id)
    test_df['video_id'] = test_df['rgb_frame'].apply(extract_video_id)
    
    # Check for video overlap
    train_videos = set(train_df['video_id'])
    val_videos = set(val_df['video_id'])
    test_videos = set(test_df['video_id'])
    
    train_val_overlap = train_videos & val_videos
    train_test_overlap = train_videos & test_videos
    val_test_overlap = val_videos & test_videos
    
    print(f"\nðŸš¨ LEAKAGE DETECTED:")
    print(f"  Videos in BOTH train & val:  {len(train_val_overlap)} ({len(train_val_overlap)/len(train_videos)*100:.1f}%)")
    print(f"  Videos in BOTH train & test: {len(train_test_overlap)} ({len(train_test_overlap)/len(train_videos)*100:.1f}%)")
    print(f"  Videos in BOTH val & test:   {len(val_test_overlap)} ({len(val_videos)*100:.1f}%)")
    
    # Calculate how many FRAMES are leaked
    leaked_train_val = len(train_df[train_df['video_id'].isin(train_val_overlap)])
    leaked_train_test = len(train_df[train_df['video_id'].isin(train_test_overlap)])
    
    print(f"\n  Leaked FRAMES (trainâ†’val):  {leaked_train_val} ({leaked_train_val/len(train_df)*100:.1f}% of train)")
    print(f"  Leaked FRAMES (trainâ†’test): {leaked_train_test} ({leaked_train_test/len(train_df)*100:.1f}% of train)")
    
    # Test new (video-aware) splitting
    print("\n" + "="*70)
    print("TEST 2: Video-Aware Split (Fixed Method)")
    print("="*70)
    
    train_df_fixed, val_df_fixed, test_df_fixed = create_stratified_splits(
        csv_path,
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15,
        seed=seed,
        use_video_aware=True  # New method
    )
    
    # Expected results
    print(f"\nâœ“ Expected Results:")
    print(f"  - Lower initial F1 scores (0.6-0.7 instead of 0.9)")
    print(f"  - Slower convergence (5-10 epochs instead of 1-2)")
    print(f"  - Final F1 ~0.85-0.92 (more realistic than 0.9999)")
    
    # Performance impact estimate
    print(f"\n" + "="*70)
    print("ESTIMATED PERFORMANCE IMPACT")
    print("="*70)
    
    if len(train_val_overlap) > 0:
        leakage_severity = len(train_val_overlap) / len(train_videos)
        
        if leakage_severity > 0.5:
            severity = "SEVERE"
            emoji = "ðŸ”´"
        elif leakage_severity > 0.2:
            severity = "MODERATE"
            emoji = "ðŸŸ¡"
        else:
            severity = "MILD"
            emoji = "ðŸŸ¢"
        
        print(f"{emoji} Leakage Severity: {severity}")
        print(f"\nWith video-aware splitting, expect:")
        print(f"  â€¢ Initial epoch F1: 0.60-0.70 (vs current 0.90)")
        print(f"  â€¢ Final F1 (teacher): 0.88-0.95 (vs current 0.9999)")
        print(f"  â€¢ Final F1 (student): 0.82-0.90 (vs current 0.9935)")
        print(f"  â€¢ More realistic generalization to new scenes")
    
    print("\n" + "="*70)
    print("RECOMMENDATIONS")
    print("="*70)
    print("1. Re-train ALL models using video-aware splitting")
    print("2. The fix is already enabled by default (use_video_aware=True)")
    print("3. Delete old results and re-run the ablation study")
    print("4. Report both results in your paper as a comparison")
    print("="*70)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Diagnose data leakage in video frame datasets')
    parser.add_argument('--csv', type=str, required=True, help='Path to CSV file')
    parser.add_argument('--seed', type=int, default=42, help='Random seed')
    args = parser.parse_args()
    
    diagnose_data_leakage(args.csv, args.seed)
